{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in c:\\python\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = Path(os.getcwd())\n",
    "root = current_path.parent.absolute()\n",
    "data_folder = str(root) + '/raw data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- XLSX FILES --\n",
      "Betting Against Beta Equity Factors Daily sheets:\n",
      "-->BAB Factors\n",
      "-->HML Devil\n",
      "\n",
      "bloom_data_2 sheets:\n",
      "-->CL1\n",
      "-->CL2\n",
      "-->CL3\n",
      "-->Euribor3\n",
      "-->Bund10\n",
      "-->FUTURES MATURITIES\n",
      "\n",
      "Quality Minus Junk Factors Daily sheets:\n",
      "-->QMJ Factors\n",
      "-->HML Devil\n",
      "\n",
      "Value and Momentum Everywhere Factors Monthly sheets:\n",
      "-->VME Factors\n",
      "\n",
      "Volatility_data_treated sheets:\n",
      "-->Sheet1\n",
      "\n",
      "\n",
      "-- XLS FILES --\n",
      "sentiment sheets:\n",
      "-->SENTIMENT\n",
      "\n",
      "\n",
      "-- csv FILES --\n",
      "F-F_Momentum_Factor_daily\n",
      "F-F_Research_Data_5_Factors_2x3_daily\n",
      "F-F_ST_Reversal_Factor_daily\n",
      "\n",
      "-- CSV FILES --\n",
      "F-F_Momentum_Factor_daily\n",
      "F-F_Research_Data_5_Factors_2x3_daily\n",
      "F-F_ST_Reversal_Factor_daily\n"
     ]
    }
   ],
   "source": [
    "types = [\"xlsx\", \"csv\", \"xls\"]\n",
    "\n",
    "os.chdir(data_folder)\n",
    "\n",
    "tanguy = {}\n",
    "\n",
    "print(\"-- XLSX FILES --\")\n",
    "for file_path in glob(\"*.xlsx\"):\n",
    "    file_name = file_path.split(\".\")[0]\n",
    "    if file_name == 'giga_base':break\n",
    "\n",
    "    print(file_name + \" sheets:\")\n",
    "    \n",
    "    file = pd.ExcelFile(file_path)\n",
    "    for sheet in file.sheet_names:\n",
    "        print(\"-->\"+sheet)\n",
    "        tanguy[sheet] = file.parse(sheet)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "print(\"\\n-- XLS FILES --\") \n",
    "for file_path in glob(\"*.xls\"):\n",
    "    file_name = file_path.split(\".\")[0]\n",
    "\n",
    "    print(file_name + \" sheets:\")\n",
    "    \n",
    "    file = pd.ExcelFile(file_path)\n",
    "    for sheet in file.sheet_names:\n",
    "        print(\"-->\"+sheet)\n",
    "        tanguy[sheet] = file.parse(sheet)\n",
    "    print()\n",
    "    \n",
    "print(\"\\n-- csv FILES --\")\n",
    "for file_path in glob(\"*.csv\"):\n",
    "    file_name = file_path.split(\".\")[0]\n",
    "    print(file_name)\n",
    "    file_df = pd.read_csv(file_path, sep=';')\n",
    "    tanguy[file_name] = file_df\n",
    "\n",
    "print(\"\\n-- CSV FILES --\")\n",
    "for file_path in glob(\"*.CSV\"):\n",
    "    file_name = file_path.split(\".\")[0]\n",
    "    print(file_name)\n",
    "    file_df = pd.read_csv(file_path, sep=';')\n",
    "    tanguy[file_name] = file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Intersect avec dates VIX\n",
    "# Donnés monthly à intersect\n",
    "# supprimer value and momentum\n",
    "\n",
    "keys = list(tanguy.keys())\n",
    "for key in keys:\n",
    "    if key !='FUTURES MATURITIES':\n",
    "        if type(tanguy[key].index)!=pd.DatetimeIndex:\n",
    "            date_col = [col for col in ['Date','DATE','Unnamed: 0','Reported data', 'time'] if col in tanguy[key].columns]\n",
    "            assert len(date_col)==1, \"Date column is not unique\"+ str( key)\n",
    "            if key in ['F-F_ST_Reversal_Factor_daily', 'F-F_Research_Data_5_Factors_2x3_daily', 'F-F_Momentum_Factor_daily']:\n",
    "                tanguy[key][date_col]= tanguy[key][date_col].applymap(lambda x: datetime.strptime(x,'%d/%m/%Y'))\n",
    "            tanguy[key].set_index(date_col, inplace=True)\n",
    "            if key == 'VME Factors':\n",
    "                # Resampling monthly -> daily\n",
    "                #The value for month n is the one released on the last day of the month n-1, as it is one agents use during month n.\n",
    "                start_date = tanguy[\"VME Factors\"].index.min() - pd.DateOffset(day=1)\n",
    "                end_date = tanguy[\"VME Factors\"].index.max() + pd.DateOffset(day=31)\n",
    "                dates = pd.date_range(start_date, end_date, freq='D')\n",
    "                tanguy[\"VME Factors\"] = tanguy[\"VME Factors\"].reindex(dates, method='ffill')\n",
    "        tanguy[key].index.names = [\"Date\"]\n",
    "        #Adding a suffix\n",
    "        tanguy[key].rename(columns = lambda x: x+'_'+key,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CL1\n",
      "CL2\n",
      "CL3\n",
      "Euribor3\n",
      "Bund10\n",
      "FUTURES MATURITIES\n",
      "QMJ Factors\n",
      "VME Factors\n",
      "Sheet1\n",
      "SENTIMENT\n",
      "F-F_Momentum_Factor_daily\n",
      "F-F_Research_Data_5_Factors_2x3_daily\n",
      "F-F_ST_Reversal_Factor_daily\n"
     ]
    }
   ],
   "source": [
    "#Now merging everything into big_base\n",
    "\n",
    "big_base = tanguy[keys[0]]['2000':].join(tanguy[keys[1]]['2000':], how='outer')\n",
    "\n",
    "\n",
    "for key in keys[2:]:\n",
    "    print(key)\n",
    "    if key not in ['FUTURES MATURITIES']: big_base = big_base.join(tanguy[key]['2000':], how='outer')\n",
    "\n",
    "big_base.interpolate(method='time' ,axis='index', limit_area='inside', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(root)\n",
    "big_base.to_excel(str(root) + 'giga_base.xlsx', na_rep='#N/A N/A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38740d3277777e2cd7c6c2cc9d8addf5118fdf3f82b1b39231fd12aeac8aee8b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
