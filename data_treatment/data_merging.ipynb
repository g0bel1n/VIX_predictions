{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in c:\\python\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "\n",
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour harmoniser les importations en chemin relatifs, dans des fichiers cousins :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Github\\VIX\\VIX_predictions-1\\treated_data\\\n"
     ]
    }
   ],
   "source": [
    "current_path = Path(os.getcwd())\n",
    "root = current_path.parent.absolute()\n",
    "data_folder = str(root) + '\\\\treated_data\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- XLSX FILES --\n",
      "Betting Against Beta Equity Factors Daily sheets:\n",
      "-->BAB Factors\n",
      "\n",
      "bloom_data_2 sheets:\n",
      "-->CL1\n",
      "-->CL2\n",
      "-->CL3\n",
      "-->Euribor3\n",
      "-->Bund10\n",
      "-->FUTURES MATURITIES\n",
      "\n",
      "Quality Minus Junk Factors Daily sheets:\n",
      "-->QMJ Factors\n",
      "-->HML Devil\n"
     ]
    }
   ],
   "source": [
    "types = [\"xlsx\", \"csv\", \"xls\"]\n",
    "\n",
    "os.chdir(data_folder)\n",
    "\n",
    "sheets_dict = {}\n",
    "\n",
    "print(\"-- XLSX FILES --\")\n",
    "for file_path in glob(\"*.xlsx\"):\n",
    "    file_name = file_path.split(\".\")[0]\n",
    "\n",
    "\n",
    "    print(file_name + \" sheets:\")\n",
    "    \n",
    "    file = pd.ExcelFile(file_path)\n",
    "    for sheet in file.sheet_names:\n",
    "        print(\"-->\"+sheet)\n",
    "        sheets_dict[sheet] = file.parse(sheet)\n",
    "    print()\n",
    "    \n",
    "    \n",
    "print(\"\\n-- XLS FILES --\") \n",
    "for file_path in glob(\"*.xls\"):\n",
    "    file_name = file_path.split(\".\")[0]\n",
    "\n",
    "    print(file_name + \" sheets:\")\n",
    "    \n",
    "    file = pd.ExcelFile(file_path)\n",
    "    for sheet in file.sheet_names:\n",
    "        print(\"-->\"+sheet)\n",
    "        sheets_dict[sheet] = file.parse(sheet)\n",
    "    print()\n",
    "    \n",
    "print(\"\\n-- csv FILES --\")\n",
    "for file_path in glob(\"*.csv\"):\n",
    "    file_name = file_path.split(\".\")[0]\n",
    "    print(file_name)\n",
    "    file_df = pd.read_csv(file_path, sep=';')\n",
    "    sheets_dict[file_name] = file_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Date column is not uniquevolatility",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16836/627153200.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msheets_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mdate_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'DATE'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Unnamed: 0'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Reported data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msheets_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate_col\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Date column is not unique\"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'F-F_ST_Reversal_Factor_daily'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'F-F_Research_Data_5_Factors_2x3_daily'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'F-F_Momentum_Factor_daily'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0msheets_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdate_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0msheets_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdate_col\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'%d/%m/%Y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Date column is not uniquevolatility"
     ]
    }
   ],
   "source": [
    "\n",
    "# Intersect avec dates VIX\n",
    "# Donnés monthly à intersect\n",
    "# supprimer value and momentum\n",
    "\n",
    "keys = list(sheets_dict.keys())\n",
    "for key in keys:\n",
    "    if key !='FUTURES MATURITIES':\n",
    "        if type(sheets_dict[key].index)!=pd.DatetimeIndex:\n",
    "            date_col = [col for col in ['Date','DATE','Unnamed: 0','Reported data', 'time'] if col in sheets_dict[key].columns]\n",
    "            assert len(date_col)==1, \"Date column is not unique\"+ str( key)\n",
    "            if key in ['F-F_ST_Reversal_Factor_daily', 'F-F_Research_Data_5_Factors_2x3_daily', 'F-F_Momentum_Factor_daily']:\n",
    "                sheets_dict[key][date_col]= sheets_dict[key][date_col].applymap(lambda x: datetime.strptime(x,'%d/%m/%Y'))\n",
    "            sheets_dict[key].set_index(date_col, inplace=True)\n",
    "            if key == 'VME Factors':\n",
    "                # Resampling monthly -> daily\n",
    "                #The value for month n is the one released on the last day of the month n-1, as it is one agents use during month n.\n",
    "                start_date = sheets_dict[\"VME Factors\"].index.min() - pd.DateOffset(day=1)\n",
    "                end_date = sheets_dict[\"VME Factors\"].index.max() + pd.DateOffset(day=31)\n",
    "                dates = pd.date_range(start_date, end_date, freq='D')\n",
    "                sheets_dict[\"VME Factors\"] = sheets_dict[\"VME Factors\"].reindex(dates, method='ffill')\n",
    "        sheets_dict[key].index.names = [\"Date\"]\n",
    "        #Adding a suffix\n",
    "        sheets_dict[key].rename(columns = lambda x: x+'_'+key,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['BAB Factors', 'CL1', 'CL2', 'CL3', 'Euribor3', 'Bund10', 'FUTURES MATURITIES', 'QMJ Factors', 'HML Devil', 'Sheet1', 'SENTIMENT', 'F-F_Momentum_Factor_daily', 'F-F_Research_Data_5_Factors_2x3_daily', 'F-F_ST_Reversal_Factor_daily'])\n"
     ]
    }
   ],
   "source": [
    "keys = sheets_dict.keys()\n",
    "print(keys)\n",
    "# final_base = pd.merge_asof(sheets_dict[keys[0]], sheets_dict[keys[1]], on=\"Date\")\n",
    "\n",
    "#     big_base = pd.merge_asof(big_base, index_n_vol['VSTOXX'], on=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'big_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12948/1740950242.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbig_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'database.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_rep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'#N/A N/A'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'big_base' is not defined"
     ]
    }
   ],
   "source": [
    "os.chdir(root)\n",
    "big_base.to_excel(str(root) + 'database.xlsx', na_rep='#N/A N/A')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38740d3277777e2cd7c6c2cc9d8addf5118fdf3f82b1b39231fd12aeac8aee8b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
